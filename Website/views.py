"""
Here we create the page templates for our webpages.
These templates help us to take care of the requests generated by the webpages.
"""

# Create your views here.
from .forms import AudioForm
from django.shortcuts import render

import numpy as np
import librosa
import librosa.display
from tensorflow.keras.models import load_model
from io import BytesIO
import base64
import os
import matplotlib.pyplot as plt
from PIL import Image

from Website.melspec import plot_colored_polar
from Website.util import *

# CONSTANTS
CAT6 = ['fear', 'angry', 'neutral', 'happy', 'sad', 'surprise']
CAT7 = ['fear', 'disgust', 'neutral', 'happy', 'sad', 'surprise', 'angry']
CAT3 = ["positive", "neutral", "negative"]

TEST_CAT = ['fear', 'disgust', 'neutral', 'happy', 'sad', 'surprise', 'angry']
TEST_PRED = np.array([.3, .3, .4, .1, .6, .9, .1])
model_type = "mfccs"
em3 = em6 = em7 = gender = True

cwd = os.getcwd() 
module_dir = cwd + "\\Website"
file_path = module_dir + '\\model3.h5'
model = load_model(file_path)
media_dir = os.getcwd() + '\\media\\documents\\'
model1_path = module_dir + '\\model4.h5'
model2_path = module_dir + '\\model_mw.h5'


def Audio_store(request):
    msg = {
        "message": "Please upload audio.",
        "show": False
    }

    if request.method == 'POST': 
        form = AudioForm(request.POST,request.FILES or None) 
        if form.is_valid(): 
            
            c = form.save() 
            try:
                output = {}
                filename = str(c.record).split('/')[-1]
                path = media_dir + filename

                if_save_audio = 0
                if if_save_audio == 1:
                    output['message'] = "File size is too large. Try another file."
                elif if_save_audio == 0:
                    try:
                        # Load the audio as flotind point array and further processing
                        wav, sr = librosa.load(path, sr=44100)
                        print("ok")
                        Xdb = get_melspec(path)[1]
                        mfccs = librosa.feature.mfcc(wav, sr=sr)

                        fig = plt.figure(figsize=(10, 2))
                        fig.set_facecolor('#d1d1e0')
                        plt.title("Wave-form")
                        librosa.display.waveplot(wav, sr=44100)
                        plt.gca().axes.get_yaxis().set_visible(False)
                        plt.gca().axes.get_xaxis().set_visible(False)
                        plt.gca().axes.spines["right"].set_visible(False)
                        plt.gca().axes.spines["left"].set_visible(False)
                        plt.gca().axes.spines["top"].set_visible(False)
                        plt.gca().axes.spines["bottom"].set_visible(False)
                        plt.gca().axes.set_facecolor('#d1d1e0')
                        plt.tight_layout()

                        # Convert the figure to web-readble format.
                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')

                        output['waveplot'] = graphic
                        
                        # MFCCs Plot
                        fig = plt.figure(figsize=(10, 2))
                        fig.set_facecolor('#d1d1e0')
                        plt.title("MFCCs")
                        librosa.display.specshow(mfccs, sr=sr, x_axis='time')
                        plt.gca().axes.get_yaxis().set_visible(False)
                        plt.gca().axes.spines["right"].set_visible(False)
                        plt.gca().axes.spines["left"].set_visible(False)
                        plt.gca().axes.spines["top"].set_visible(False)
                        plt.tight_layout()

                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')
                        output['specshow'] = graphic

                        # Mel-log Spectogram
                        fig2 = plt.figure(figsize=(10, 2))
                        fig2.set_facecolor('#d1d1e0')
                        plt.title("Mel-log-spectrogram")
                        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')
                        plt.gca().axes.get_yaxis().set_visible(False)
                        plt.gca().axes.spines["right"].set_visible(False)
                        plt.gca().axes.spines["left"].set_visible(False)
                        plt.gca().axes.spines["top"].set_visible(False)

                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')

                        output['specshowlog'] = graphic

                        # Emotion Prediction
                        mfccs = get_mfccs(path, model.input_shape[-1])
                        mfccs = mfccs.reshape(1, *mfccs.shape)
                        pred = model.predict(mfccs)[0]

                        pos = pred[3] + pred[5] * .5
                        neu = pred[2] + pred[5] * .5 + pred[4] * .5
                        neg = pred[0] + pred[1] + pred[4] * .5
                        data3 = np.array([pos, neu, neg])

                        # 3 Emotion Prediction
                        txt = "MFCCs - 3 Emotions\n" + get_title(data3, CAT3)
                        fig = plt.figure(figsize=(5, 5))
                        COLORS = color_dict(COLOR_DICT)
                        plot_colored_polar(fig, predictions=data3, categories=CAT3,
                                            title=txt, colors=COLORS)
                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')
                        output['predict3'] = graphic

                        # 6 Emotion Prediction
                        txt = "MFCCs - 6 Emotions\n" + get_title(pred, CAT6)
                        fig2 = plt.figure(figsize=(5, 5))
                        COLORS = color_dict(COLOR_DICT)
                        plot_colored_polar(fig2, predictions=pred, categories=CAT6,
                                            title=txt, colors=COLORS)
                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')
                        output['predict6'] = graphic

                        # 7 Emotion Prediction
                        model_ = load_model(model1_path)
                        mfccs_ = get_mfccs(path, model_.input_shape[-2])
                        mfccs_ = mfccs_.T.reshape(1, *mfccs_.T.shape)
                        pred_ = model_.predict(mfccs_)[0]
                        txt = "MFCCs - 7 Emotions\n" + get_title(pred_, CAT7)
                        fig3 = plt.figure(figsize=(5, 5))
                        COLORS = color_dict(COLOR_DICT)
                        plot_colored_polar(fig3, predictions=pred_, categories=CAT7,
                                            title=txt, colors=COLORS)
                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')
                        output['predict7'] = graphic

                        # Gender Prediction
                        gmodel = load_model(model2_path)
                        gmfccs = get_mfccs(path, gmodel.input_shape[-1])
                        gmfccs = gmfccs.reshape(1, *gmfccs.shape)
                        gpred = gmodel.predict(gmfccs)[0]
                        gdict = [["female", "woman.png"], ["male", "man.png"]]
                        ind = gpred.argmax()
                        txt = "Predicted gender: " + gdict[ind][0]
                        img = Image.open("static/" + gdict[ind][1])

                        fig4 = plt.figure(figsize=(3, 3))
                        fig4.set_facecolor('#d1d1e0')
                        plt.title(txt)
                        plt.imshow(img)
                        plt.axis("off")
                        buffer = BytesIO()
                        plt.savefig(buffer, format='png')
                        buffer.seek(0)
                        image_png = buffer.getvalue()
                        buffer.close()

                        graphic = base64.b64encode(image_png)
                        graphic = graphic.decode('utf-8')
                        output['predictgender'] = graphic
                    except Exception as e:
                        output['message'] = f"Error {e}"
                else:
                    output['message'] = "Unknown error"

                for i in output:
                    msg[i] = output[i]
                    print(output[i])
            except:
                # Form Invalidated
                print("not ok")
                return render(request, "upload.html", msg)


            msg['message'] = "Please wait for the predictions to load..."
            msg['show'] = True
            return render(request, "upload.html", msg)

    else: 
        # When the reauest method is not POST
        form = AudioForm() 
        msg['form'] = form
    return render(request, 'upload.html', msg)


def homePage(request):
    """
    This template handles the requests generated by the home page of the website.
    """

    return render(request, "home.html", {})


def record(request):
    """
    This template handles the requests generated by record page.
    """

    return render(request, "record.html", {"message": "Record the audio and download it in .wav format."})


def about(request):
    """
    This template handles the requests generated by the about page of the website.
    It displays information about the project and links to the resources that were used to create it.
    """
    
    return render(request, "about.html", {})

